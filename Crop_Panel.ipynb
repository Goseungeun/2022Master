{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "708d82ec-e8a8-4c2a-a63d-7b2933df19bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from matplotlib import image\n",
    "import numpy as np\n",
    "import skimage.io\n",
    "import argparse\n",
    "from sklearn.cluster import DBSCAN\n",
    "import pixellib\n",
    "from skimage.color import rgb2gray, rgb2hsv\n",
    "from skimage.filters import sobel\n",
    "from skimage import morphology\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import glob\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3db814d0-243b-4e0f-af33-5722def87e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def order_points(pts):\n",
    "    # initialzie a list of coordinates that will be ordered\n",
    "    # such that the first entry in the list is the top-left,\n",
    "    # the second entry is the top-right, the third is the\n",
    "    # bottom-right, and the fourth is the bottom-left\n",
    "    rect = np.zeros((4, 2), dtype = \"float32\")\n",
    "    \n",
    "    # the top-left point will have the smallest sum, whereas\n",
    "    # the bottom-right point will have the largest sum\n",
    "    s = pts.sum(axis = 1)\n",
    "    rect[0] = pts[np.argmin(s)]\n",
    "    rect[2] = pts[np.argmax(s)]\n",
    "    \n",
    "    # now, compute the difference between the points, the\n",
    "    # top-right point will have the smallest difference,\n",
    "    # whereas the bottom-left will have the largest difference\n",
    "    diff = np.diff(pts, axis = 1)\n",
    "    rect[1] = pts[np.argmin(diff)]\n",
    "    rect[3] = pts[np.argmax(diff)]\n",
    "    \n",
    "    # return the ordered coordinates\n",
    "    return rect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68c02fe3-f725-417a-89f1-311d932d04f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def four_point_transform(image, pts):\n",
    "    # obtain a consistent order of the points and unpack them\n",
    "    # individually\n",
    "    rect = order_points(pts)\n",
    "    (tl, tr, br, bl) = rect\n",
    "    \n",
    "    # compute the width of the new image, which will be the\n",
    "    # maximum distance between bottom-right and bottom-left\n",
    "    # x-coordiates or the top-right and top-left x-coordinates\n",
    "    widthA = np.sqrt(((br[0] - bl[0]) ** 2) + ((br[1] - bl[1]) ** 2))\n",
    "    widthB = np.sqrt(((tr[0] - tl[0]) ** 2) + ((tr[1] - tl[1]) ** 2))\n",
    "    maxWidth = max(int(widthA), int(widthB))\n",
    "    \n",
    "    # compute the height of the new image, which will be the\n",
    "    # maximum distance between the top-right and bottom-right\n",
    "    # y-coordinates or the top-left and bottom-left y-coordinates\n",
    "    heightA = np.sqrt(((tr[0] - br[0]) ** 2) + ((tr[1] - br[1]) ** 2))\n",
    "    heightB = np.sqrt(((tl[0] - bl[0]) ** 2) + ((tl[1] - bl[1]) ** 2))\n",
    "    maxHeight = max(int(heightA), int(heightB))\n",
    "    \n",
    "    # now that we have the dimensions of the new image, construct\n",
    "    # the set of destination points to obtain a \"birds eye view\",\n",
    "    # (i.e. top-down view) of the image, again specifying points\n",
    "    # in the top-left, top-right, bottom-right, and bottom-left\n",
    "    # order\n",
    "    dst = np.array([\n",
    "        [0, 0],\n",
    "        [maxWidth - 1, 0],\n",
    "        [maxWidth - 1, maxHeight - 1],\n",
    "        [0, maxHeight - 1]], dtype = \"float32\")\n",
    "    \n",
    "    # compute the perspective transform matrix and then apply it\n",
    "    M = cv.getPerspectiveTransform(rect, dst)\n",
    "    warped = cv.warpPerspective(image, M, (maxWidth, maxHeight))\n",
    "    \n",
    "    # return the warped image\n",
    "    return warped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82ff91c3-e0fe-47d4-b0ee-db6267740009",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    names = []\n",
    "    print(\"load images\")\n",
    "    for filename in tqdm(os.listdir(folder)):\n",
    "        img = cv.imread(os.path.join(folder,filename))\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "            names.append(filename)\n",
    "    return images, names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79c7e559-6fa2-4a7c-9478-b2caddf41a68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [00:00<00:00, 122.06it/s]\n",
      "100%|██████████| 36/36 [00:00<00:00, 418.31it/s]\n"
     ]
    }
   ],
   "source": [
    "# Read original images \n",
    "orig_images = load_images_from_folder(\"D:\\\\pytorch-CycleGAN-and-pix2pix\\\\dataset\\\\dust_dataset\\\\dust\")\n",
    "names = orig_images[1]\n",
    "conv_image = []\n",
    "\n",
    "# Cropping parameters\n",
    "#pts_w = np.array(eval(\"(174, 438), (1377, 443), (1695, 807), (219, 829)\"), dtype = \"float32\")\n",
    "# pts_1 = np.array(eval(\"(173,437),(467,438),(513,596),(196,599)\"), dtype = \"float32\")\n",
    "# pts_2 = np.array(eval(\"(196,627),(520,622),(577,821),(218,830)\"), dtype = \"float32\")\n",
    "# pts_3 = np.array(eval(\"(503,438),(779,439),(854,594),(551,594)\"), dtype = \"float32\")\n",
    "# pts_4 = np.array(eval(\"(558,622),(867,620),(962,815),(622,819)\"), dtype = \"float32\")\n",
    "# pts_5 = np.array(eval(\"(739,288),(982,291),(1066,418),(800,415)\"), dtype = \"float32\")\n",
    "# pts_6 = np.array(eval(\"(814,439),(1081,441),(1185,594),(892,595)\"), dtype = \"float32\")\n",
    "# pts_7 = np.array(eval(\"(904,620),(1202,618),(1334,811),(1007,814)\"), dtype = \"float32\")\n",
    "# pts_8 = np.array(eval(\"(1015,292),(1251,294),(1359,420),(1100,419)\"), dtype = \"float32\")\n",
    "# pts_9 = np.array(eval(\"(1117,441),(1375,442),(1507,594),(1223,595)\"), dtype = \"float32\")\n",
    "# pts_10 = np.array(eval(\"(1241,618),(1527,617),(1698,809),(1377,812)\"), dtype = \"float32\")\n",
    "pts_11 = np.array(eval(\"(80,22),(187,37),(151,159),(19,138)\"), dtype = \"float32\")\n",
    "\n",
    "#cropped_path = \"D:\\\\ACE_8panels\"\n",
    "# cropped_path1 = \"D:\\\\ACE_1\"\n",
    "# cropped_path2 = \"D:\\\\ACE_2\"\n",
    "# cropped_path3 = \"D:\\\\ACE_3\"\n",
    "# cropped_path4 = \"D:\\\\ACE_4\"\n",
    "# cropped_path5 = \"D:\\\\ACE_5\"\n",
    "# cropped_path6 = \"D:\\\\ACE_6\"\n",
    "# cropped_path7 = \"D:\\\\ACE_7\"\n",
    "# cropped_path8 = \"D:\\\\ACE_8\"\n",
    "# cropped_path9 = \"D:\\\\ACE_9\"\n",
    "# cropped_path10 = \"D:\\\\ACE_10\"\n",
    "cropped_path11 = \"D:\\\\pytorch-CycleGAN-and-pix2pix\\\\dataset\\\\dust_dataset\\\\testB\"\n",
    "\n",
    "for img_count in tqdm(range(len(orig_images[0]))):\n",
    "    \n",
    "    # Read original image\n",
    "    image1 = cv.cvtColor(orig_images[0][img_count],\n",
    "                         cv.COLOR_BGR2RGB)\n",
    "    # Cropping\n",
    "    #warpedimg = four_point_transform(image1, pts_w)\n",
    "    # img_1 = four_point_transform(image1,pts_1)\n",
    "    # img_2 = four_point_transform(image1,pts_2)\n",
    "    # img_3 = four_point_transform(image1,pts_3)\n",
    "    # img_4 = four_point_transform(image1,pts_4)\n",
    "    # img_5 = four_point_transform(image1,pts_5)\n",
    "    # img_6 = four_point_transform(image1,pts_6)\n",
    "    # img_7 = four_point_transform(image1,pts_7)\n",
    "    # img_8 = four_point_transform(image1,pts_8)\n",
    "    # img_9 = four_point_transform(image1,pts_9)\n",
    "    # img_10 = four_point_transform(image1,pts_10)\n",
    "    img_11 = four_point_transform(image1,pts_11)\n",
    "    \n",
    "    im_name = names[img_count]\n",
    "    \n",
    "    # Save cropped image\n",
    "    #cv.imwrite(cropped_path+'\\\\'+im_name, cv.cvtColor(warpedimg, cv.COLOR_BGR2RGB),[int(cv.IMWRITE_JPEG_QUALITY), 100])\n",
    "    # cv.imwrite(cropped_path1+'\\\\'+im_name, cv.cvtColor(img_1, cv.COLOR_BGR2RGB),[int(cv.IMWRITE_JPEG_QUALITY), 100])\n",
    "    # cv.imwrite(cropped_path2+'\\\\'+im_name, cv.cvtColor(img_2, cv.COLOR_BGR2RGB),[int(cv.IMWRITE_JPEG_QUALITY), 100])\n",
    "    # cv.imwrite(cropped_path3+'\\\\'+im_name, cv.cvtColor(img_3, cv.COLOR_BGR2RGB),[int(cv.IMWRITE_JPEG_QUALITY), 100])\n",
    "    # cv.imwrite(cropped_path4+'\\\\'+im_name, cv.cvtColor(img_4, cv.COLOR_BGR2RGB),[int(cv.IMWRITE_JPEG_QUALITY), 100])\n",
    "    # cv.imwrite(cropped_path5+'\\\\'+im_name, cv.cvtColor(img_5, cv.COLOR_BGR2RGB),[int(cv.IMWRITE_JPEG_QUALITY), 100])\n",
    "    # cv.imwrite(cropped_path6+'\\\\'+im_name, cv.cvtColor(img_6, cv.COLOR_BGR2RGB),[int(cv.IMWRITE_JPEG_QUALITY), 100])\n",
    "    # cv.imwrite(cropped_path7+'\\\\'+im_name, cv.cvtColor(img_7, cv.COLOR_BGR2RGB),[int(cv.IMWRITE_JPEG_QUALITY), 100])\n",
    "    # cv.imwrite(cropped_path8+'\\\\'+im_name, cv.cvtColor(img_8, cv.COLOR_BGR2RGB),[int(cv.IMWRITE_JPEG_QUALITY), 100])\n",
    "    # cv.imwrite(cropped_path9+'\\\\'+im_name, cv.cvtColor(img_9, cv.COLOR_BGR2RGB),[int(cv.IMWRITE_JPEG_QUALITY), 100])\n",
    "    # cv.imwrite(cropped_path10+'\\\\'+im_name, cv.cvtColor(img_10, cv.COLOR_BGR2RGB),[int(cv.IMWRITE_JPEG_QUALITY), 100])\n",
    "    cv.imwrite(cropped_path11+'\\\\'+im_name, cv.cvtColor(img_11, cv.COLOR_BGR2RGB),[int(cv.IMWRITE_JPEG_QUALITY), 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e348cdc8-59ed-4730-8fb1-a83e58d40dd7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
